[see also Feature request #14992 on the bug tracker]

The current binary lingen program sucks in just about every respect.

Parallelism
Memory consumption
Middle products
Pclmulqdq
Transform caching, and tuning
Linear system solving

************************************************************************
* Fact 1.

The binary lingen program is not parallel. I have tried to add openmp
parallelism at the most obvious places (like computation of Fourier
transforms for all entries in a matrix), but unfortunately, for reasons I
do not understand, this crashes. See /ceph/thome/lingen.log . I suspect
that there would be a benefit in making sure that openmp limits the
number of threads, but my attempts so far with the environment variables
OMP_THREAD_LIMIT and OMP_NUM_THREADS (I don't know which does what) have
also failed. The real thing to do anyway would be to provide multi node
parallelism, as is done with plingen.

Action 1 (done in commit 0586c99)
========

Making the OMP patch work should be doable within a reasonable amount of
time, I expect.

Action 2
========

The best option as far as parallelism is concerned is to use the plingen
code structure. This cannot be done before the inner arithmetic gets a
review.


************************************************************************
* Fact 2.

Memory consumption of the program is totally insane. For a 12g input,
very soon more than 150gb are needed, and I truly fear that at the end of
the day, the memory needed could be much much worse, notably because of
Fourier transforms at the top level. As it is now, we are forced to run
the program on barbecue, which is the only machine we have with a really
large amount of memory.

No action currently, since bitrot is the main problem at this point.

************************************************************************
* Fact 3: inner arithmetic sucks.

Middle products appear in the course of the computation. They are done
the dumb way in lingen, full product + truncation. None of the back-ends
used for polynomial multiplication provide a middle product interface. It
is not critical, but there is both time and memory footprint to be saved
by doing it better.

Pclmulqdq is of course critical to having fast binary polynomial
multiplication. Alas, barbecue does not support it.

For choosing the transforms to be used, three options are theoretically
supported.
- Cantor (c128) the base field being GF(2^128). The innermost operation
  therefore cares a great deal about pclmulqdq.
- ternary fft (gf2x-tfft).
- "fake" which defines DFT and IFT as copies, and uses gf2x_mul in the
  middle.

As terribly stupid as it may seem, the default is "fake" (see
compute_lingen). (seems terribly stupid at least in terms of memory !)
There is a cantor_threshold argument to lingen, but by default the
threshold is "never". Reasons for that are that cantor pays off much
earlier with pclmul, and probably also because at some point I had a bug
with the c128 interface. Unfortunately I don't recall what it was. But
despite that, activation of Cantor seems much desirable. The lack of
activation for the gf2x-tfft layer really looks like a bug also.

Note added 25 Nov 2015: cantor_threshold seems to work, and
cantor_threshold=1024 be close to optimal.

There is a bench_polmatmul program (here, the arguments needed are:
bench_polmatmul 132000000 512 256). It examines what it takes to do the
polynomial matrix multiplies, which are half of the above-leaves work
(the other half being MPs), while the work at the leaves of the recursion
is small linear algebra. Running this program shows that we would gain a
lot by enabling cantor, and enacting reasonable parallelism.

At the leaves of the recursion, we have small (512x768) binary linear
system solving (PLUQ-like). Currently, this seems to represent too much
time. I am confident that improvement is possible here as well.

Update: on a c125, 94% of the total time spent in the leaves (go_quadratic)
is spent in extract_coeff_degree_t(), and only 6% in gauss().

Action 3
========

much to do here.

We identify two operations we have to perform.

 - products of matrices of size (m+n)*(m+n), with polynomial entries. We
   may assume at least that 32 divides m and n, maybe even 64.
   The polynomials in there have degree within the range 10^3 to 10^7,
   hardly ever more.
 - middle products matrices with polynomial entries, this time with size
   m*(m+n) and (m+n)*(m+n). The middle product is not balanced.

The strategy, first, is to:

(assuming we go for matrices of polynomials, because nowadays we have
pclmulqdq)

 WP 1.
   1a - write complete specifications and a test suite for the file
        lingen-matpoly.c (which deals with matrices having polynomial
        entries over GF(p) !).
   1b - convert this test suite to what we expect for base field GF(2).
   1c - write a new file, e.g. lingen-matpoly-binary.c, and in particular the
        functions matpoly_addmp and matpoly_addmul ; those are critical.
   1d - First functionality test: enabling this from plingen so that we
        get a validation. This might imply disabling the bigmatpoly
        layer.
   Preparing 1d can conceivably be independent from the rest.

 WP 2.
   2a - specifications and tests for lingen-matpoly-ft.c
   2b - updated test suite
   2c - lingen-matpoly-ft-binary.c ; we might focus on c128 to start with.
   2d - validation check.

   Again, preparing 2d can conceivably be independent from the rest.

 WP 3.
   3a-3d - same for lingen-bigmatpoly.c and lingen-bigmatpoly-ft.c

