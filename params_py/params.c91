###########################################################################
#     Parameter file for Cado-NFS
###########################################################################

# This file is a sample parameter file for a 91-digit gnfs input

# Anything after a # is a comment, until end of line.
# Any empty line is ignored
#
# Each parameter should be on an individual line, like
#   param0=42.17

# Some parameters apply to all steps of the algorithm (General parameters
# below), and are related to the execution environment. Some other
# parameters control the many different tunables of the execution of the
# algorithm. Such parameters are relevant to only one of the steps of NFS, and
# are thus listed under the section related to the corresponding
# binary. Each of the section corresponding to one step in particular
# also contains a couple of parameters relative to the execution
# environment (for that step only).

###########################################################################
# General parameters
###########################################################################

# General parameters are relevant to the cadofactor.pl script only.

# This script may be used as: cadofactor.pl wdir=... name=... n=...

# - location and name of files -
# All files created by cadofactor.pl will be put into <wdir> and its
# subdirectories.
name = c91
# All files created by cadofactor will be prefixed by this name.

# - parallel computation -
# computation
# The cadofactor.pl script has the ability to spawn jobs on many
# machines using ssh, in a master/slave manner. For this to work, a
# machines description file is mandatory.
# This is only used in the polynomial selection and sieving steps.
# Only the master machine needs access to the <wdir> directory
# (unless MPI is used for the linear algebra step).
# Slave machines put their temporary data in the <tmpdir> specified on a
# per-(group of)machine basis in the machines description file.

###########################################################################
# Polynomial selection with Kleinjung's algorithm (2008)
###########################################################################

tasks.polyselect.degree = 4		# degree of the algebraic polynomial
tasks.polyselect.P = 16000		# choose lc(g) with two prime factors in [P,2P]
# Setting a large value will most likely find better polynomials,
# but the number of found polynomials will be smaller.
# As a rule of thumb, we want at least 100 found polynomials in total
# (without norm limitation, see below).
tasks.polyselect.maxnorm = 33.4		# max. lognorm of polynomials (before rootsieve)
# If not set, a default value of 1e9 (in practice infinity) is used.
# Setting this value right might speed up a lot the polynomial
# selection, by discarding right away polynomials which are not
# promising. As a rule of thumb, we want at least 10 polynomials
# in total below this bound.
tasks.polyselect.admin = 0		# min value for lc(f)
# If not set, the default is 0.
tasks.polyselect.admax = 50000		# max value for lc(f)
# The polynomial selection search time is proportional to the
# length of the interval [polsel_admin,polsel_admax]
tasks.polyselect.adrange = 5000		# individual tasks
# Polynomial selection is split into several individual tasks. The
# complete range from polsel_admin to polsel_admax has to be covered for the
# polynomial selection to complete. The number of individual tasks is
# obviously (polsel_admax-polsel_admin)/polsel_adrange. 
tasks.polyselect.incr = 60		# forced divisor of lc(f)
tasks.polyselect.nq = 1000
# This factor is usually a smooth number, which forces projective roots in
# the algebraic polynomial. 60 is a good start, 210 is popular as well.
# This controls the computational effort put into the rotation step.
# The higher this value is, the better the found polynomial will be,
# but it will take more time.

# - runtime environment parameters for polyselect -
# The existence of result files from polyselect jobs is checked at
# regular intervals. Tune this parameter to check more/less
# frequently.
# This sets the posix ``nice level'' for polyselect jobs. If you
# don't know what it is, you may leave as is, or set to 0.

###########################################################################
# Sieve
###########################################################################

# (r,a) means rational or algebraic side
rlim = 200000
alim = 400000
# rlim/alim are the factor base bounds. The number of rational (resp.
# algebraic) primes is roughly rlim/log(rlim) (resp. alim/log(rlim))
lpbr = 24
lpba = 24
# lpbr/lpba is the (base 2 log of the) large prime bound
tasks.sieve.mfbr = 48
tasks.sieve.mfba = 48
# mfbr/mfba is the (base 2 log of the) limit for the cofactor we try
# to split into large primes.
tasks.sieve.rlambda = 2.1
tasks.sieve.alambda = 2.2
# rlambda/alambda is the early-abort ratio: if after sieving, and
# subtracting from the base 2 log of the norm the contribution of the
# sieved primes, the remaining approximate of the base 2 log of the
# norm is larger than lambda times lpb, we reject.
# Note that this has in particular the effect that if e.g. rlambda <
# some integer k+1, then at most k large primes are allowed on the
# rational side. It is customary, when at most k large primes are
# allowed, to set rlambda to e.g. k + 0.2, in order to compensate for
# inaccuracies due to sieving.

tasks.sieve.I = 11		# Sieving range in lattice siever
# The lattice siever sieves over a range in the (i,j) plane which is
# 2^I times 2^(I-1), to put things simply (some rescaling may change
# this, but the size of the sieve area remains constant). Increasing
# I by 1 multiplies the amount of required RAM for the siever by a
# factor of 4.
tasks.sieve.ratq = 0
tasks.sieve.qmin = 400000		# Start of the special-q range
# The ratq parameters specifies whether or not the special q is to be
# taken on the rational side (ratq=1) or on the algebraic side
# (ratq=0).  qmin is usually above the corresponding factor base
# bound, but this is not a requirement.
# ratq should be set on the side where the largest norms are
# expected. As a very rough rule of thumb, this means ratq=0 for gnfs
# runs, and on some occasions ratq=1 for snfs runs.

tasks.sieve.qrange = 20000		# The size of an elementary sieving task
# The sieving process is split into many individual tasks. This
# parameter controls the size of individual tasks.

tasks.sieve.rels_wanted = 1660000		# Start of filtering tries
# We only try to do filtering (and thus check if we have enough relations)
# once we have accumulated <firstcheck> relations (including duplicates).
# A rule of thumb is to use 1.6*N/log(N) if N=2^n when lpba=lpbr=n, or
# 0.8*2^lpba/log(2^lpba) + 0.8*2^lpbrlog(2^lpbr) when lpba <> lpbr.
# The default value is 1, which means that with checkrange=1 filtering
# tries are done at the very beginning of the sieving.
# Make sure to update <firstcheck> whenever you update lpba or lpbr.

# Each time <checkrange> new relations have been imported by
# cadofactor.pl, a test is done to see whether enough relations have
# been collected or not. It is usual to set it to 1 (= always do the
# check) for small factorizations, but obviously it would be
# counter-productive to do this check too often for large
# factorizations. Note that this check is performed on the host
# running the cadofactor.pl script, and does require a significant
# amount of RAM.

tasks.sieve.threads = 2
# The lattice siever program las may run in a multithreaded manner.
# This keeps the amount of memory used constant, and just runs
# faster.

# - runtime environment -
# The existence of result files from siever jobs is checked at
# regular intervals. Tune this parameter to check more/less
# frequently.
slaves.niceness = 10		# nice level for the sieving jobs
# This sets the posix ``nice level'' for polyselect jobs. If you
# don't know what it is, you may leave as is, or set to 0.

###########################################################################
# Filtering
###########################################################################

# there. If non-zero (and parallel=1), we incorporate all
# new relations in the current sieving jobs (which are killed),
# and do another filtering step with those relations.
# The default behaviour is 0.

tasks.filter.purge.keep = 160		# maximal excess wanted after purge
# (purge shrinks if needed)
tasks.filter.maxlevel = 15		# perform up to <maxlevel>-way merges
tasks.filter.ratio = 1.1		# used only when bwstrat=0 (see below)
tasks.filter.merge.forbw = 3		# bwstrat=0: stops the merge when the weight of
tasks.merge.coverNmax = 100
#    the matrix multiplied by the number of rows c*N
#    exceeds ratio*min(c*N)
# bwstrat=1: stops when the product c*N is minimal
#    (more exactly when it increases 20 times in a row)
# bwstrat=3: stops when the average number of non-zero
#    coefficients c/N exceeds coverNmax (default 100)

###########################################################################
# Linear algebra
###########################################################################

# - runtime environment -
# cadofactor.pl supports only running the linear system solving on the
# host running cadofactor.pl itself, using posix threads. More advanced
# usage has to go by hand.
tasks.linalg.bwc.threads = 2x2		# Multithreading level of Block-Wiedemann ; Use
# <m>x<n> for bwc, or only one integer for bw.
tasks.linalg.bwc.interval = 100		# checkpointing interval for bwc.
tasks.linalg.bwc.interleaving = 0
tasks.linalg.bwc.mn = 64
tasks.linalg.bwc.shuffled_product = 1

###########################################################################
# Characters
###########################################################################

tasks.linalg.characters.nchar = 50		# number of characters
tasks.linalg.characters.threads = 2
