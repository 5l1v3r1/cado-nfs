#ifndef BUCKET_H_
#define BUCKET_H_

/*
 * Bucket sieving: radix-sort sieve updates as they are created.
 */

#include <stdint.h>
#include "cado-endian.h"
// #define SAFE_BUCKETS
#ifdef SAFE_BUCKETS
#include <stdio.h>
#include "portability.h"
#endif
#include "misc.h"
#include "fb-types.h"
#include "fb.h"

/*
 * This bucket module provides a way to store elements (that are called
 * updates), while partially sorting them, according to some criterion (to
 * be defined externally): the incoming data is stored into several
 * buckets. The user says for each data to which bucket it belongs. This
 * module is supposed to perform this storage in a cache-friendly way and
 * so on...
 */

/*
 * Main available commands are 
 *   push_bucket_update(i, x)  :   add x to bucket number i
 *   get_next_bucket_update(i) :   iterator to read contents of bucket number i
 *
 * See the MAIN FUNCTIONS section below for the complete interface, with
 * prototypes of exported functions.
 */

/********  Data structure for the contents of buckets **************/

/* In principle, the typedef for the bucket_update can be changed without
 * affecting the rest of the code. 
 */

/*
 * For the moment, we store the bucket updates and a 16-bit field
 * that can contain, for instance, the low bits of p.
 */

/* THE ORDER IS MANDATORY! */
typedef struct {
#ifdef CADO_LITTLE_ENDIAN
    slice_offset_t hint;
    uint16_t x;
#else
    uint16_t x;
    slice_offset_t hint;
#endif
} bucket_update_shorthint_t;

/* Same than previous, but 1 byte more for indirection.
   Careful: this byte is the first in little endian, and
   the last byte in big endian.
   k = kilo bucket */
typedef uint8_t k_bucket_update_shorthint_t[1 + sizeof(bucket_update_shorthint_t)];

/* Same than previous, but with 2 bytes (double 1 byte indirections).
   m = mega bucket */
typedef uint8_t m_bucket_update_shorthint_t[2 + sizeof(bucket_update_shorthint_t)];


/* An update with the complete prime, generated by line re-sieving */

typedef struct {
    uint16_t x;
    uint32_t p;
} bucket_update_prime_t;

/* When purging a bucket, we don't store pointer arrays to indicate where in
   the puged data a new slice begins, as each slice will have only very few
   updates surviving. Instead, we re-write each update to store both slice
   index and offset. */

typedef struct {
    uint16_t x;
    slice_index_t index;
    slice_offset_t hint;
} bucket_update_longhint_t;


/*
 * will be used as a sentinel
 */
static const bucket_update_shorthint_t LAST_UPDATE = {0,0};

/******** Bucket array typedef **************/
/******** Bucket array implementation **************/
template <typename UPDATE_TYPE>
struct bucket_array_t : private NonCopyable {
  UPDATE_TYPE *big_data;
  size_t big_size;                    // size of bucket update memory

  UPDATE_TYPE ** bucket_write;    // Contains pointers to first empty
                                      // location in each bucket
  UPDATE_TYPE ** bucket_start;    // Contains pointers to beginning of
                                      // buckets
  UPDATE_TYPE ** bucket_read;     // Contains pointers to first unread
                                      // location in each bucket
  slice_index_t    * slice_index;     // For each slice that gets sieved,
                                      // new index is added here
  UPDATE_TYPE ** slice_start;     // For each slice there are
                                      // n_bucket pointers, each pointer
                                      // tells where in the corresponding 
                                      // bucket the updates from that slice
                                      // start
  uint32_t           n_bucket;        // Number of buckets
  uint64_t           bucket_size;     // The allocated size of one bucket.
  size_t             size_b_align;    // (sizeof(void *) * n_bucket + 63) & ~63
                                      // to align bucket_* on cache line
  slice_index_t      nr_slices;       // Number of different slices
  slice_index_t      alloc_slices;    // number of checkpoints (each of size
                                      // size_b_align) we have allocated

  static const slice_index_t initial_slice_alloc = 256;
  static const slice_index_t increase_slice_alloc = 128;

private:
  /* Get a pointer to the pointer-set for the i_slice-th slice */
  UPDATE_TYPE ** get_slice_pointers(const slice_index_t i_slice) const {
    ASSERT_ALWAYS(i_slice < nr_slices);
    ASSERT_ALWAYS(size_b_align % sizeof(UPDATE_TYPE *) == 0);
    return (slice_start + i_slice * size_b_align / sizeof(UPDATE_TYPE *));
  }
  size_t nb_of_updates(const int i) const {
      return (bucket_write[i] - bucket_start[i]);
  }
  void realloc_slice_start(size_t);
public:
  /* Constructor sets everything to zero, and does not allocate memory.
     allocate_memory() does all the allocation. */
  bucket_array_t();
  /* Destructor frees memory, if memory was allocated. If it wasn't, it's
     basically a no-op, except for destroying the bucket_array_t itself. */
  ~bucket_array_t();

  /* Lacking a move constructor before C++11, we make a fake one. We use this
     to store the bucket_array_t on the stack in fill_in_buckets(), to remove
     one level of pointer dereferencing.
     This method copies all the fields of other, then sets them to 0 in other.
     Deconstructing the other bucket_array_t after move() is a no-op, as if
     other had been constructed, but never run allocate_memory(). */
  void move(bucket_array_t &other);

  /* Allocate enough memory to be able to store at least _n_bucket buckets,
     each of at least _bucket_size entries. If at least as much memory had
     already been allocated, does not resize it.  */
  void allocate_memory(const uint32_t _n_bucket, const size_t _bucket_size,
                       const slice_index_t prealloc_slices = initial_slice_alloc);
  /* Return a begin iterator over the UPDATE_TYPE entries in i_bucket-th
     bucket, generated by the i_slice-th slice */
  const UPDATE_TYPE *begin(const size_t i_bucket, const slice_index_t i_slice) const {
    ASSERT_ALWAYS(i_slice < nr_slices);
    return get_slice_pointers(i_slice)[i_bucket];
  }
  /* Return an end iterator over the UPDATE_TYPE entries in i_bucket-th
     bucket, generated by the i_slice-th slice */
  const UPDATE_TYPE *end(const size_t i_bucket, const slice_index_t i_slice) const {
    ASSERT_ALWAYS(i_slice < nr_slices);
    return (i_slice + 1 < nr_slices) ? get_slice_pointers(i_slice + 1)[i_bucket] :
      bucket_write[i_bucket];
  }

  void reset_pointers();
  slice_index_t get_slice_index(const slice_index_t i_slice) const {
    ASSERT_ALWAYS(i_slice < nr_slices);
    return slice_index[i_slice];
  }
  void add_slice_index(const slice_index_t new_slice_index) {
    /* Write new set of pointers for the new factor base slice */
    ASSERT_ALWAYS(nr_slices <= alloc_slices);
    if (nr_slices == alloc_slices) {
      /* We're out of allocated space for the checkpoints. Realloc to bigger
         size. We add space for increase_slice_alloc additional entries. */
      realloc_slice_start(increase_slice_alloc);
    }
    aligned_medium_memcpy((uint8_t *)slice_start + size_b_align * nr_slices, bucket_write, size_b_align);
    slice_index[nr_slices++] = new_slice_index;
  }
  double max_full () const;
  void push_bucket_update(const int i, const UPDATE_TYPE update) {
      *bucket_write[i]++ = update; /* Pretty! */
      if (0)
        printf("Pushed (x=%u, hint=%u) to bucket %d, nr_slices = %u\n",
               update.x, update.hint, i, (unsigned int) nr_slices);
#ifdef SAFE_BUCKETS
      if (bucket_start[i] + bucket_size <= bucket_write[i]) {
          fprintf(stderr, "# Warning: hit end of bucket nb %d\n", i);
          bucket_write[i]--;
      }
#endif
  }
};

/* Same than previous, for kilo & mega buckets in fill_in_k/m_buckets.
   These buckets are used only for 2 and 3 sort passes buckets */ 
typedef struct {
  k_bucket_update_shorthint_t ** bucket_write;
  k_bucket_update_shorthint_t ** bucket_start;
  k_bucket_update_shorthint_t ** logp_idx;
  uint32_t             n_bucket;
  uint64_t             bucket_size;
  size_t               size_b_align;
} k_bucket_array_t;

typedef struct {
  m_bucket_update_shorthint_t ** bucket_write;
  m_bucket_update_shorthint_t ** bucket_start;
  m_bucket_update_shorthint_t ** logp_idx;
  uint32_t             n_bucket;
  uint64_t             bucket_size;
  size_t               size_b_align;
} m_bucket_array_t;


/* A class that stores updates in a single "bucket".
   It's really just a container class with pre-allocated array for storage,
   a persistent read and write pointer. */
template <class UPDATE_TYPE>
class bucket_single {
  UPDATE_TYPE *start; /* start is a "strong" reference */
  UPDATE_TYPE *read;  /* read and write are "weak" references into the allocated memory */
  UPDATE_TYPE *write;
  size_t _size;
public:
  bucket_single (const size_t size) : _size(size)
  {
    start = new UPDATE_TYPE[size];
    read = start;
    write = start;
  }

  ~bucket_single() {
    delete[] start;
    start = read  = write = NULL;
    _size = 0;
  }

  /* A few of the standard container methods */
  const UPDATE_TYPE * begin() const {return start;}
  const UPDATE_TYPE * end() const {return write;}
  size_t size() const {return write - start;}

  /* Main writing function: appends update to bucket number i.
   * If SAFE_BUCKETS is not #defined, then there is no checking that there is
   * enough room for the update. This could lead to a segfault, with the
   * current implementation!
   */
  void push_update (const UPDATE_TYPE &update)
  {
      *(write++) = update;
#ifdef SAFE_BUCKETS
      if (start + _size <= write) {
          fprintf(stderr, "# Warning: hit end of bucket\n");
          write--;
      }
#endif
  }
  const UPDATE_TYPE &get_next_update () {
#ifdef SAFE_BUCKETS
    ASSERT_ALWAYS (read < write);
#endif
    return *read++; 
  }
  void rewind_by_1() {if (read > start) read--;}
  bool is_end() const { return read == write; }

  void sort ();
};

/* Stores info containing the complete prime instead of only the low 16 bits */

class bucket_primes_t : public bucket_single<bucket_update_prime_t> {
    typedef bucket_single<bucket_update_prime_t> super;
public:  
  bucket_primes_t (const size_t size) : super(size){}
  ~bucket_primes_t(){}
  void purge (const bucket_array_t<bucket_update_shorthint_t> &BA, 
          int i, const fb_part *fb, const unsigned char *S);
};

/* Stores info containing both slice index and offset instead of only the offset */

class bucket_array_complete : public bucket_single<bucket_update_longhint_t> {
    typedef bucket_single<bucket_update_longhint_t> super;
public:  
  bucket_array_complete (const size_t size) : super(size){}
  ~bucket_array_complete(){}
  void purge (const bucket_array_t<bucket_update_shorthint_t> &BA, int i, const unsigned char *S);
};


/* Compute a checksum over the bucket region.

   We import the bucket region into an mpz_t and take it modulo
   checksum_prime. The checksums for different bucket regions are added up,
   modulo checksum_prime. This makes the combined checksum independent of
   the order in which buckets are processed, but it is dependent on size of
   the bucket region. Note that the selection of the sieve region, i.e., of J
   depends somewhat on the number of threads, as we want an equal number of
   bucket regions per thread. Thus the checksums are not necessarily
   comparable between runs with different numbers of threads. */

class sieve_checksum {
  static const unsigned int checksum_prime = 4294967291u; /* < 2^32 */
  unsigned int checksum;
  void update(const unsigned int);

  public:
  sieve_checksum() : checksum(0) {}
  unsigned int get_checksum() {return checksum;}

  /* Combine two checksums */ 
  void update(const sieve_checksum &other) {
    /* Simply (checksum+checksum2) % checksum_prime, but using
       ularith_addmod_ul_ul() to handle sums >= 2^32 correctly. */
    this->update(other.checksum);
  }
  /* Update checksum with the pointed-to data */
  void update(const unsigned char *, size_t);
};

#endif	/* BUCKET_H_ */
