TO SIEVE ON A CLUSTER IN MODE BESTEFFORT

$cdir : working directory on the cluster
$ldir : working directory on the local machine

I) on the cluster :
- create the following directory :
$cdir/inqueue : waiting list.
$cdir/inprogress : list of progress jobs.
$cdir/working_rels : relations files of progress jobs.
$cdir/results_rels : relations files completed (no compressed).
$cdir/output_rels : relations files ready to move to local machine.
$cdir/log_oar : logfile oarsub cmd. 
$cdir/scripts
$cdir/bin

- copy $name.poly and $name.roots in $cdir.
  copy las_1job, las_loop, dispatcher and clean.pl in $cdir/scripts.
  edit las_1job and adjust the variables NAME (=$name) and OPT.
  edit dispatcher and adjust the variable nb_jobs_by_node
    ( $nb_cores / 2  with -mt 2 in las by defaut )
  copy las, cut_n_roots in $cdir/bin.

- run cut_n_roots to create waiting list:
$ cd $cdir/inqueue
$ ../bin/cut_n_roots -q0 $q0 -q1 $q1 -N $N | xargs touch
  (split [q0, q1[ into maximal intervals of N special q's each)
NB : fill the inqueue directory step-by-step to avoid that it contains
     a lot of files.

- run several jobs oarsub:
$ cd $cdir/log_oar
$ oarsub "$wdir/scripts/dispatcher $wdir/scripts/las_loop" -l nodes=20,walltime=24
-t besteffort -t idempotent -n $name_20
$ oarsub "$wdir/scripts/dispatcher $wdir/scripts/las_loop" -l nodes=20,walltime=24
-t besteffort -t idempotent -n $name_20
...

- clean several times by day the killed jobs because of the besteffort
mode:
$ $cdir/scripts/clean.pl



II) on the local machine :
- create the following directory :
$ldir/output_rels : as on a cluster.
$ldir/merge_rels : relations files merged.
$ldir/scripts
$ldir/bin

- copy $name.poly, $name.roots and $name.freerels.gz in $ldir.
  copy check_dup_purge.pl, merge.pl and cpu_time.pl in $ldir/scripts.
  copy check_rels, dup1, dup2, purge and roots in $ldir/bin.

- after a 'clean.pl' on the cluster, synchronize the output_rels
  directories:
$ rsync -av $name_cluster:$cdir/output_rels/ $ldir/output_rels/

- merges the relations files:
$ $ldir/scripts/merge.pl $ldir/output_rels/ -o $ldir/merge_rels/ -n $name --range $q0-$q1
  (merge the relations files between $q0 and $q1 by interval of 1 million)
NB : you can clean the files in the output_rels directories step-by-step 
     to avoid that they contain a lot of files.

- verify that you have enough of relations :
$ $ldir/scripts/check_dup_purge.pl
  (execute check_rels, dup1, dup2 and purge)
NB : don't kill the script during check_rels and dup1.

- if you have enough of relations : 
$ touch $ldir/$name.polysel_done $ldir/$name.factbase_done $ldir/$name.freerels_done $ldir/$name.sieve_done $ldir/$name.dup_done $ldir/$name.purge_done
then run cadofactor.pl.

- run cpu_time.pl to estimate the total cpu time for sieving.
$ $ldir/cpu_time.pl
